<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Packet-Based Path Tracer Project</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        h1, h2 { color: #2C3E50; }
        pre { background: #F5F5F5; padding: 10px; border-radius: 5px; overflow-x: auto; }
        a { color: #2980B9; text-decoration: none; }
    </style>
</head>
<body>
    <h1>Packet-Based Path Tracer Project</h1>
    <h3>Ashley Czumak (aczumak) and Kenechukwu Echezona (kechezon)</h3>
    
    <h2>Summary</h2>
    <p>We plan to implement a packet based path tracer in Scotty3D, parallelizing the work with OpenMP for coarse grained threading across multiple CPU cores, and ISPC for fine grained SIMD acceleration within ray packets. Our implementation will traverse a Bounding Volume Hierarchy (BVH) tree, reducing redundant intersection tests and improving cache coherence. We plan to demonstrate rendering of scenes with multiple light ray bounces and soft shadows, comparing performance between single threaded, OpenMP only, and OpenMP and ISPC versions on a multi-core CPU machine.</p>

    <h2>Background</h2>
    <p>Our project parallelizes path tracing in Scotty3D, a graphics renderer from the CMU course 15-362: Computer Graphics, that computes pixel colors by simulating light transport through a scene. The main data structure includes a Bounding Volume Hierarchy (BVH), which organizes scene geometry hierarchically using bounding boxes, and ray packets, which store groups of rays for coherent traversal. The primary operations on these structures are ray BVH intersection tests and ray triangle intersection tests, performed through the tree until leaf nodes are reached. The computationally expensive portion is the traversal of the BVH and intersection testing for millions of rays per frame, which is highly amenable to parallelization because each ray (or packet of rays) can be traced independently. The workload is broken down into packets of pixels, with dependencies only occurring when updating the final image buffer, which can be managed safely using atomic operations. This shows coarse grained data parallelism across packets for multi core execution via OpenMP, and fine grained SIMD parallelism within packets using ISPC. Ray packets improve memory locality because coherent rays traverse similar nodes in the BVH, which cache misses. Overall, the algorithm has high parallelism, is largely data parallel, 
        and is ideal for SIMD execution because of the uniform operations performed across rays in a packet.</p>
    
    
    <h2>The Challenge</h2>
    <p>The challenge of this optimization problem is balancing parallelism, memory efficiency, and algorithmic correctness. Traversing the BVH with ray packets can cause branch divergence when rays in a packet follow different paths, this effectively reduces SIMD efficiency. Large scenes also affect the CPU cache, and maintaining memory locality during traversal is very important for efficiency. Additionally, packets require varying amounts of work due to differences in ray bounces and geometry complexity, making load balancing across threads important. Ensuring thread-safe writes to the image buffer and selecting an optimal packet size to maximize SIMD utilization while preserving ray coherence complicates the problem. Overall, the difficulty is in maximizing parallel throughput, minimizing divergence, and maintaining the correct rendering.</p>
    
    <h2>Resources</h2>
    <pre>
        Scotty 3D is graphics software package that includes components for software rastization, interactive mesh editing, realistic path tracing, and dynamic animation. We will use Kenechukwu's Scotty3D A3 (from 15-362) raytracing as a base for packet tracing .\\\\

OpenMP would be used to parallelize the path tracing workload across multiple CPU cores by distributing packets of pixels or blocks of the image among threads. Each thread can independently trace its assigned rays through the scene and update the corresponding pixels in the output buffer. Dynamic scheduling could be applied to balance workload when some regions require more ray bounces, this would make all cores stay busy and the rendering would be efficient.\\\\

ISPC would be used to accelerate the computation within each ray packet by leveraging SIMD. Instead of processing rays one at a time, a packet of rays is processed simultaneously, performing BVH intersection tests and shading calculations in parallel using the CPU’s SIMD units. This reduces branch divergence, allowing each core to trace multiple coherent rays at once with high efficiency.\\\\

Other resources include Henrique who is a TA for CMU's Visual Computing Systems class. He is very familiar with computer graphics and the Scotty3D code base and we have used him to discuss what is and isn't possible in the given time that we have. 
    </pre>

    <h2>Platform Choice</h2>
    <p>Development and testing for this project will be conducted on the Gates computers because they support AVX SIMD instructions. These machines are sufficient for implementing and debugging the packet-based path tracer, testing correctness, and running small and medium sized scenes. Gates computers will also be beneficial for running large tests and evaluating the maximum achievable speedup with OpenMP and ISPC parallelization. While these machines are not required for our project, they will allow us to measure performance scaling and verify that the optimizations perform as expected under tests that have high workloads.</p>

    <h2>Schedule</h2>
    <pre>
        1. Week 1
• Familiarize with Scotty3D PathTracer module and BVH implemen-
tation.
• Test that code compiles and renders simple scenes correctly.
• Plan ray packet data structures and how they fit into existing Path-
Tracer code.
• Implement basic ray packet structure.
• Refactor tracing loop to process packets instead of single rays.
• Test correctness.
• Profile current implementation to identify BVH traversal bottlenecks.
• Experiment with small packet sizes and verify memory locality im-
provements.
• Begin implementing OpenMP parallelization across packets.
2. Week 2
• Complete OpenMP integration and test multi-threaded packet trac-
ing. 
• Compare single-threaded vs. OpenMP performance.
• Debug thread safety issues in image buffer updates.
3. Week 3 (Intermediate Milestone Deadline)
• Update Scotty3D GUI to support Packet Trace Functionality
• Debug OpenMP Implementation
• Prepare an intermediate report / demo.
• Show:
– Basic packet tracing working
– OpenMP speedup
– ISPC vectorization in progress
4. Final Days
• Introduce ISPC for fine grained SIMD acceleration within each packet.
vs. vector width).
<!--• Optimize memory layout for cache efficiency (SoA vs. AoS).-->
• Profile OpenMP + ISPC implementation.
• Verify performance improvements on benchmark scenes.
• Vectorize BVH intersection and shading routines for packets.
• Test correctness and compare to scalar implementation.
<!-- • Tune packet size for optimal SIMD performance (balance coherence)
• Address performance bottlenecks identified in milestone demo.
• Implement any remaining shading or bounce logic.
• Ensure correctness for complex scenes.
• Final profiling and optimization.-->
• Generate benchmark comparisons: single-threaded, OpenMP, OpenMP+ISPC.
• Prepare visual demo scenes for final deliverable.
• Final touches to code and documentation.
<!--• Focus on finishing final deliverable.
• Test on target machine to verify reproducibility and performance.-->
• Final run of packet-based path tracer.
• Showcase the real-time or accelerated rendering of complex scenes.
• Highlight speedup metrics (OpenMP vs. OpenMP+ISPC)
    </pre>


<h2>Milestone Goals</h2>
<pre>
50% Goal: Functional Baseline
- Implement a correct single threaded ray–box intersection kernel in C++ BVH for baseline performance.
- Build a test harness that measures throughput.

75% Goal: Basic Parallel Speedup via OpenMP
- Integrate OpenMP parallelization over base sequential implementation
- Target: 2–4× speedup vs baseline.

100% Goal: Full Optimization (Core Deliverable)
- Add a basic ISPC kernel for ray box intersections (BVH traversal), and support ISPC option in Scotty3D Software
- Integrate OpenMP parallelization over ray packets in relevant areas (ray bounces and light computation).
- Edit Scotty3D Application to support Path Tracing Parallelization Options in GUI (none, OpenMP over single rays, OpenMP over packets, OpenMP + ISPC over packets)
- Target: 5–8× speedup vs baseline.

125% Goal: Full Optimization
- Tune ISPC kernels and OpenMP scheduling.
- Profile and optimize BVH traversal.
- Target: 8–10× speedup.

150% Goal: Advanced Optimizations
- Compare array of structures to structure of arrays memory layout.
- Manual prefetching, cache-blocking, alignment.
- Target: 10–15× speedup.

<!-- 100% Goal: Full Optimization (Core Deliverable)
- Tune ISPC kernels and OpenMP scheduling.
- Compare array of structures to structure of arrays memory layout.
- Profile and optimize BVH traversal.
- Target: 5–10× speedup vs baseline.

125% Goal: Advanced Optimizations
- Manual prefetching, cache-blocking, alignment.
- Target: 10–12× speedup.

150% Goal
- Ray sorting/packetization (e.g., Morton order).
- Target: 12–15× speedup.
    
150% Goal 
- Hybrid ISPC + OpenMP pipelined work queues or task based parallelism.
- Wide packet tracing, NUMA aware scheduling.
- Target: 15–20×+ speedup and polished visual demo.-->

</pre>

<h2>Team Division</h2>
<pre>
    Both members collaborated during the first two stages, but Ashley Czumak had to leave the project due to health reasons.

- Stage 1: Baseline Implementation
  • Work together on testing the serial BVH traversal and ray box/triangle intersection.
  • Jointly design ray packet data structures and test correctness.

- Stage 2: Initial Parallelism
  • Together integrate OpenMP parallel for and test multicore scaling.
  • Write basic ISPC kernels and verifying SIMD correctness.

- Stage 3: Full Parallel Optimization
  • Jointly profile the code and identify hotspots.
  • Optimize data layout, memory access, cache locality, and scheduling.
  • Try different ISPC vector widths, OpenMP scheduling, and BVH traversal together.

- Stage 4: Advanced Optimization
  • Implement ray sorting, packet coherence improvements, and branch divergence reduction.
  • Add prefetching and architecture.

- Stage 5: Stretch 
  • Jointly build hybrid ISPC + OpenMP pipelines or task based parallelism.
  • Collaborate on polishing the final demo for the parallelism competition.

</pre>
    
</body>
</html>
